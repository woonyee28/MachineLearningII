{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1600925966214,
     "user": {
      "displayName": "EMILIO PARRADO HERNANDEZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu-OvX6osyVq8b7J4Xa7D7HiZ61sPYwKqgPxyJ=s64",
      "userId": "09506376050266996513"
     },
     "user_tz": -120
    },
    "id": "lXyR3B1-cst0"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from IPython.core.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1600925966486,
     "user": {
      "displayName": "EMILIO PARRADO HERNANDEZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu-OvX6osyVq8b7J4Xa7D7HiZ61sPYwKqgPxyJ=s64",
      "userId": "09506376050266996513"
     },
     "user_tz": -120
    },
    "id": "McTkC40Tcst3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1600925966487,
     "user": {
      "displayName": "EMILIO PARRADO HERNANDEZ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghu-OvX6osyVq8b7J4Xa7D7HiZ61sPYwKqgPxyJ=s64",
      "userId": "09506376050266996513"
     },
     "user_tz": -120
    },
    "id": "lopz8Y9Ccst6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8pLlMwKcst8"
   },
   "source": [
    "## Degree in Data Science and Engineering, group 96\n",
    "## Machine Learning 2\n",
    "### Fall 2023\n",
    "\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "# Lab 2. Support Vector Machines for Classification\n",
    "\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "**Emilio Parrado Hern√°ndez**\n",
    "\n",
    "Dept. of Signal Processing and Communications\n",
    "\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src='http://www.tsc.uc3m.es/~emipar/BBVA/INTRO/img/logo_uc3m_foot.jpg' width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "\n",
    "In this assignment you will work with an adaptation of the UCI repository dataset [segmentation]('https://archive.ics.uci.edu/ml/datasets/image+segmentation'). It is a binary classification task (labels are $+1$ and $-1$, respectively).\n",
    "\n",
    "The following cell loads the data and constructs the corresponding training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt('segmentation.data', delimiter=',')\n",
    "X_train = train_data[:,1:]\n",
    "y_train = train_data[:,0]\n",
    "test_data = np.loadtxt('segmentation.test', delimiter=',')\n",
    "X_test = test_data[:,1:]\n",
    "y_test = test_data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Linear SVC\n",
    "\n",
    "The first method we are going to use to solve the problem is a SVM endowed with a **linear kernel**. The performance of this model depends on the value of the regularization hyperparameter $C$.\n",
    "\n",
    "## 1.1- Validation the hard way\n",
    "\n",
    "In order to find which is the best value of $C$ in order to achieve the best generalization (a great performance on the test set without using the test set we are implementing the following **validation the hard way** procedure:\n",
    "\n",
    "- Split **the training dataset** in two subsets:\n",
    "    - actual training subset (70% of the data): `Xr` (observations) and `Yr` (targets)\n",
    "    - validation subset (30% of the data): `Xv` and `Yv`\n",
    "\n",
    "- Define `v_C` as a list with the following values for the parameter $C$: $10^{-3},$ $10^{-2},$ $10^{-1},$ $1,$ $10,$ $10^3,$ and $10^4$\n",
    "\n",
    " - Define `validation_accuracy` as an empty array with size equal to the length of `v_C`.\n",
    " \n",
    " - Run a loop with one iteration per member of `v_C`. At each iteration perform the following operations:\n",
    "     - Instantiate a SVC with linear kernel and the value of $C$ corresponding to this iteration\n",
    "     - Train the SVC with `Xr` and `Yr`\n",
    "     - Evaluate the SVC with `Xv` and `Yv` and store the accuracy in the corresponding position of `validation_accuracy`\n",
    "     \n",
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell, just run it\n",
    "plt.plot(np.array(v_C), validation_accuracy, label='validation')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('C')\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- What is the value of $C$ that yields the better performance?\n",
    "\n",
    "- What is the difference between the best value and the second best?\n",
    "\n",
    "- Do you think it worths exploring larger or smaller values for $C$ (I mean, enlarging the explored range)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to check if the validation found the best parameter for the test set. In the next cell implement the following code:\n",
    "\n",
    "- Define `test_accuracy` as an empty array with size equal to the length of `v_C`.\n",
    " \n",
    " - Run a loop with one iteration per member of `v_C`. At each iteration perform the following operations:\n",
    "     - Instantiate a SVC with linear kernel and the value of $C$ corresponding to this iteration\n",
    "     - Train the SVC with `X_train` and `y_train`\n",
    "     - Evaluate the SVC with `X_test` and `y_test` and store the accuracy in the corresponding position of `test_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell, just run it\n",
    "plt.plot(np.array(v_C), validation_accuracy, label='validation')\n",
    "plt.plot(np.array(v_C), test_accuracy, label='test')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('C')\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- What is the value of $C$ that would yield the better performance in the test set?\n",
    "\n",
    "- What is the difference between the best accuracy found for the test set and the accuracy that you will obtain if you use the value of $C$ found with validation?\n",
    "\n",
    "- Do you think it worths exploring larger or smaller values for $C$ (I mean, enlarging the explored range)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.- GridSearchCV\n",
    "\n",
    "The next step is to use crossvalidation to do the hyperparameter search in a more systematic and clean way.\n",
    "\n",
    "### Grids of hyperparameters\n",
    "\n",
    "This method consists in to form a **grid** with a number of dimensions equal to the number of hyperparameters that one needs to optimize. The size of each dimension of the grid is equal to the number of values in the range of the corresponding hyperparameter. Notice that this method explores **discrete** ranges for each hyperparameter.\n",
    "\n",
    "For the SVC with linear kernel we will initially explore the following range:\n",
    "\n",
    "\n",
    "- `C` $ \\in$ $[10^{-3},$ $10^{-2},$ $10^{-1},$ $1,$ $10,$ $10^3,$  $10^4]$\n",
    "\n",
    "Notice this range determine a $7 \\times 1$ grid. \n",
    "\n",
    "In models that depend on a larger number of hyperparameters one has to be careful with the granularity of the ranges as the combinatorial explosion of the size of the grid can be hard to manage.\n",
    "\n",
    "### Cross validation \n",
    "\n",
    "Cross validation is a commonly used procedure in machine learning to simulate the effect of training a model with a set of data and evaluate its generalization capabilities as the performance in a **separate dataset**. \n",
    "\n",
    "The cross validation process involves the following steps:\n",
    "\n",
    "- Randomly partition the training dataset in $N$ disjoint subsets of similar sizes. Each of this subsets is called **fold** in machine learning jargon. Hence the term **N-fold cross validation**.\n",
    "\n",
    "- Let us suppose we have chosen $N=3$ folds. This means the training data has been split in three subsets: $(X_1, Y_1)$, $(X_2, Y_2)$ y $(X_3, Y_3)$. \n",
    "\n",
    "- Create an instance of the model with the corresponding hyperparameters. The cross validation follows with the execution of the following loop\n",
    "\n",
    "    For $n=1,2,\\dots,N$ iterations:  \n",
    "    1. Choose $(X_n,Y_n)$ as **validation set** for iteration $n$\n",
    "    2. Prepare a **training set** for iteration $n$ joining the rest of the subsets (excluding the validation set)\n",
    "    3. Fit the model instance with the training set of step 2\n",
    "    4. Evaluate  the model instance (method `score`) with the validation set of step 1\n",
    "    5. Keep the *score* achieved in the $n$ iteration.\n",
    "\n",
    "- Once the loop is finished, we have $N$ scores, each corresponding to the evaluation of the model fitted in each iteration with the corresponding validation set.\n",
    "- Estimate the **real score** that an instance of the model fitted using all the data would yield in a separate dataset computing the **mean** and **standard deviation** of the $N$ validation scores.\n",
    "\n",
    "Typical values for the number of folds include $N\\in \\{3, 5, 10\\}$\n",
    "\n",
    "\n",
    "###  Cross validation to explore the grid\n",
    "\n",
    "The grid is explored by a loop that visits all its nodes and runs a  **cross validation** to estimate the test performance that the model would yield if it were fitted using the values for hyperparameter that correspond to that node. \n",
    "\n",
    "Once all the nodes of the grid have been cross validated, the procedure outputs the combination of hyperparameters corresponding to the node with the best cross validation performance. \n",
    "\n",
    "###  Grid search in sklearn\n",
    "\n",
    "There is a module in sklearn that implements this algorithm for exploring a grid of hyperparameters with cross validation: [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell implement code that:\n",
    "- define `param_lsvc`, a dictionary that will serve as dictionary of parameters for the range of $C$\n",
    "- instantiate `grid_lsvc`, an `GridSearchCV` object with a SVC with linear kernel as estimator and `param_lsvc` as parameter dictionary.\n",
    "- Train `grid_lsvc` with `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at attribute `grid_lsvc.cv_results_` to identify fields that store:\n",
    "- the values of parameter $C$ used in each node of the grid. Store them in an array called `values_of_C`\n",
    "- the average score achieved by the model in each node of the grid. Store them in an array called `Mean_acc`\n",
    "- the standard deviation of the scores achieved by the model in each node of the grid. Store them in an array called `Std_acc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell, just run it\n",
    "plt.plot(values_of_C, Mean_acc, label='mean validation', color='blue')\n",
    "plt.fill_between(values_of_C, \n",
    "                 Mean_acc - Std_acc, \n",
    "                 Mean_acc + Std_acc,\n",
    "                 label='std validation',\n",
    "                 alpha=0.2, \n",
    "                 color='blue')\n",
    "plt.plot(values_of_C, test_accuracy, label='test', color='green')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('C')\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- What is the value of $C$ that suggest GridSearchCV?\n",
    "\n",
    "- What is the difference between the best accuracy found for the test set and the accuracy that you will obtain if you use the value of $C$ found by GridSearchCV?\n",
    "\n",
    "- Is there any significant difference between GridSearchCV and validation the hard way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.- Running times\n",
    "\n",
    "GridSearchCV also provides with information about the times needed to train and to evaluate the algorithm. Identify what are the fields that provide with that information inside `grid_lsvc.cv_results_` and produce two plots, similar to the previous one in which you show:\n",
    "- plot 1: The time (in seconds) employed to train the model vs. the value of $C$\n",
    "- plot 2: The time (in seconds) employed to evaluate the model vs. the value of $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- How is the evolution of the training time with $C$?\n",
    "\n",
    "- How is the evolution of the evaluation time with $C$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Explore different kernels\n",
    "\n",
    "After obtaining results with the linear kernel, we will explore the performance of the SVM endowed with RBF and polynomial kernels.\n",
    "\n",
    "## 2.1.- RBF kernel\n",
    "\n",
    "The RBF kernel introduces a new hyperparameter in the model, the spread of the kernel $\\gamma$. We will consider the following range of values: \n",
    "$$\n",
    "\\gamma \\in [10^{-5}, 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1, 10]\n",
    "$$\n",
    "\n",
    "Therefore our crossvalidation grid search needs to expand one more dimension to allocate this range. \n",
    "\n",
    "In the next cell implement code that:\n",
    "- Defines `v_g`, an array with the range of values for `gamma`\n",
    "- Defines `param_rbf_svc`, a dictionary with the ranges of $\\gamma$ and $C$ for the SVM\n",
    "- Creates `grid_rbf_svc`, a `GridSearchCV` object with an SVC as estimator and  `param_rbf_svc` as parameter dictionary\n",
    "- Train `grid_rbf_svc` with `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to retrieve useful information from attribute `cv_results_`, in particular:\n",
    "- store in `C_values` the values of parameter $C$ used in each node of the grid\n",
    "- store in `gamma_values` the values of parameter $\\gamma$ used in each node of the grid\n",
    "- store in `Acc` the average validation score obtained in each node of the grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell, just run it\n",
    "results_rbf = (pd.DataFrame(np.vstack((C_values, \n",
    "                                 gamma_values,\n",
    "                                 Acc)).T,\n",
    "                      columns=['C','gamma','Acc'])).pivot(index='C', columns='gamma')\n",
    "\n",
    "\n",
    "results_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for iC, C in enumerate(results_rbf.index):\n",
    "    plt.plot(v_g, results_rbf.loc[C].values, label='C={0:f}'.format(C))\n",
    "plt.xscale('log')\n",
    "plt.grid()\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- What are the best values of $C$ and $\\gamma$ that yield the better performance in crossvalidation?\n",
    "\n",
    "- Do you think it worths exploring larger or smaller values for $C$ and/or $\\gamma$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearchCV object has an attribute that facilitates the identification of the best set of hyperparameters (`best_params_`) and also methods to consume the model trained with these best hyperparameters: `score()` and `predict()`.\n",
    "Print the accuracy in the test set achieved by the SVC with RBF kernel and hyperparameters found by GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- What kernel gives the best performance in the test set, after tuning the hyperparameters using crossvalidation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.- Polynomial kernel\n",
    "\n",
    "The polynomial kernel introduces a new hyperparameter in the model, the degree of the polynomial $d$. We will consider the following range of values: \n",
    "$$\n",
    "d \\in [2,3,4,5,6,7,8,9,10]\n",
    "$$\n",
    "\n",
    "Therefore our crossvalidation grid search needs to allocate this new range. \n",
    "\n",
    "In the next cell implement code that:\n",
    "- Defines `v_d`, an array with the range of values for $d$\n",
    "- Defines `param_poly_svc`, a dictionary with the ranges of $d$ and $C$ for the SVM\n",
    "- Creates `grid_poly_svc`, a `GridSearchCV` object with an SVC as estimator and  `param_poly_svc` as parameter dictionary\n",
    "- Train `grid_poly_svc` with `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to retrieve useful information from attribute `cv_results_`, in particular:\n",
    "- store in `C_values_poly` the values of parameter $C$ used in each node of the grid\n",
    "- store in `d_values` the values of parameter $d$ used in each node of the grid\n",
    "- store in `Acc_poly` the average validation score obtained in each node of the grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell, just run it\n",
    "results_poly = (pd.DataFrame(np.vstack((C_values_poly, \n",
    "                                 d_values,\n",
    "                                 Acc_poly)).T,\n",
    "                      columns=['C','d','Acc'])).pivot(columns='d', index='C')\n",
    "results_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for C in results_poly.index:\n",
    "    plt.plot(v_d, results_poly.loc[C].values, label='C={0:f}'.format(C))\n",
    "\n",
    "plt.grid()\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- What are the best values of $C$ and $d$ that yield the better performance in crossvalidation?\n",
    "\n",
    "- Do you think it worths exploring larger or smaller values for $C$ and/or $d$?\n",
    "\n",
    "- What is more critial for the performance of the classifier, the selection of $C$ or the degree?\n",
    "\n",
    "- What is the performance of the SVM with polynomial kernel and parameters tuned using crossvalidation in the test set? How does it compare with the other two kernels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- Scaling\n",
    "\n",
    "The last step in the development of the model involves a data preprocessing with a Standard Scaler. Since the scaling can affect the performance achieved by the SVC endowed by any of the three kernels, we will carry out a single validation procedure that searches the best option within the three kernels.\n",
    "\n",
    "For this purpose, in the next cell write code that:\n",
    "- defines `pipe_svc`, a `Pipeline` with a first stage that is an `StandardScaler` followed by a SVC\n",
    "- defines `param_svc` as the object needed to pass the ranges of hyperparameters to the SVC inside the Pipeline. Check the documentation of GridSearchCV and Pipeline. In essence, `param_svc` needs to be a list of three dictionaries, each dictionary with the ranges of parameters needed by each kernel.\n",
    "- Create `grid_sc_svc`, the `GridSearchCV` object with `pipe_svc` as estimator and `param_svc` as parameter dictionary\n",
    "- Train `grid_sc_svc` with `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#           #\n",
    "# YOUR CODE #\n",
    "#           #\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- What is the configuration of the best classifier found by crossvalidation?\n",
    "\n",
    "- What is the impact of the scaling in the performance of the classifier?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "lab_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
